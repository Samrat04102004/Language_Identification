# ğŸŒ Multilingual Language Identifier

[![Live Demo](https://img.shields.io/badge/ğŸš€%20Live%20Demo-Streamlit-blue?style=for-the-badge&logo=streamlit)](https://language-identification.onrender.com)
[![Python](https://img.shields.io/badge/Python-3.10+-yellow?style=for-the-badge&logo=python)](https://www.python.org/)
[![Deep Learning](https://img.shields.io/badge/Model-Stacked%20LSTM-red?style=for-the-badge&logo=tensorflow)]()

> ğŸš€ **A production-ready deep learning solution for real-time detection of 20+ languages via short text inputs.**

---

## ğŸ§  Overview

**Multilingual Language Identifier** is a powerful natural language processing (NLP) tool designed to detect over 20 languages using a deep learning model. Built with a Stacked LSTM network and deployed with a modern Streamlit interface, this project brings together robust modeling and scalable deployment.

---

## ğŸ› ï¸ Key Features

- ğŸŒ **Supports 20+ Languages:** Accurately identifies major world languages like English, Hindi, Spanish, French, Chinese, and more.
- ğŸ¤– **Deep Learning Backbone:** Powered by a Stacked LSTM neural network trained on short and long-form text.
- ğŸ“Š **Rich Visual Analytics:** Detailed Exploratory Data Analysis (EDA) and interpretability visuals included in the Jupyter notebook.
- âš¡ **Real-Time Prediction:** Fast and accurate predictions via an interactive Streamlit web interface.

---

## ğŸš€ Live Demo

ğŸ‘‰ **Try it now:** [language-identification.onrender.com](https://language-identification.onrender.com)

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ main.py # Streamlit app source code

â”œâ”€â”€ language_id_lstm_model.keras # Trained Bidirectional LSTM model

â”œâ”€â”€ tokenizer.joblib # Tokenizer for preprocessing

â”œâ”€â”€ label_encoder.joblib # Label encoder for language classes

â”œâ”€â”€ requirements.txt # Python dependencies

â”œâ”€â”€ runtime.txt # Python runtime version

â”œâ”€â”€ Dockerfile # Container setup for cloud deployment

â”œâ”€â”€ language_id_notebook.ipynb # EDA, preprocessing, and model training

â”œâ”€â”€ README.md # Project overview

---

## ğŸ’¡ How It Works

1. **Preprocessing** â€“ Text is cleaned and tokenized using a pre-fitted tokenizer.
2. **Model Inference** â€“ Sequences are passed through a trained Bidirectional LSTM network.
3. **Prediction** â€“ The model predicts the most likely language and returns a human-readable label.
4. **Display** â€“ Prediction is shown via Streamlit in real-time.

---

## ğŸ™ Acknowledgements

- ğŸ¤— [Hugging Face Datasets](https://huggingface.co/datasets)  
- [Streamlit](https://streamlit.io/)  
- [TensorFlow](https://www.tensorflow.org/)  
- [Keras](https://keras.io/)  
- [Scikit-learn](https://scikit-learn.org/)  
- [Render](https://render.com/)

---
